{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a custom dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataloader for MIL\n",
    "class PatientPatchDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with patient labels.\n",
    "            root_dir (string): Directory with all the patch files.\n",
    "        \"\"\"\n",
    "        self.labels_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.patient_ids = self.labels_frame['patient_id'].unique()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        patient_label = self.labels_frame[self.labels_frame['patient_id'] == patient_id]['label'].values[0]\n",
    "        patch_files = glob(os.path.join(self.root_dir, f'{patient_id}*.npy'))\n",
    "        # print('patient_id:', patient_id, ', label:', patient_label, ', num_patch files:', len(patch_files))\n",
    "        \n",
    "        # Initialize a list to hold all patches for the patient\n",
    "        all_patches = []\n",
    "        \n",
    "        # Iterate through each file and append its patches to all_patches\n",
    "        for file in patch_files:\n",
    "            patches_in_file = np.load(file)  # patches_in_file.shape is (x, 7, 7, 2048)\n",
    "            # flatten the patches_in_file to (x, 7*7*2048)\n",
    "            patches_in_file = patches_in_file.reshape(patches_in_file.shape[0], -1)\n",
    "            all_patches.append(patches_in_file)\n",
    "        \n",
    "        # Concatenate all patches along the first dimension\n",
    "        if all_patches:\n",
    "            all_patches = np.concatenate(all_patches, axis=0)\n",
    "        else:\n",
    "            # Handle case with no patches\n",
    "            all_patches = np.array([]).reshape(0, 100352)\n",
    "        \n",
    "        sample = {'patches': all_patches, 'label': patient_label}\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id: MCC001 , label: 0 , num_patch files: 1\n",
      "Batch 1\n",
      "Shape of patches: torch.Size([1, 8, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 8\n",
      "=====================================\n",
      "patient_id: MCC002 , label: 1 , num_patch files: 1\n",
      "Batch 2\n",
      "Shape of patches: torch.Size([1, 11, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 11\n",
      "=====================================\n",
      "patient_id: MCC003 , label: 0 , num_patch files: 1\n",
      "Batch 3\n",
      "Shape of patches: torch.Size([1, 8, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 8\n",
      "=====================================\n",
      "patient_id: MCC007 , label: 1 , num_patch files: 1\n",
      "Batch 4\n",
      "Shape of patches: torch.Size([1, 6, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 6\n",
      "=====================================\n",
      "patient_id: MCC008 , label: 1 , num_patch files: 3\n",
      "Batch 5\n",
      "Shape of patches: torch.Size([1, 42, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 42\n",
      "=====================================\n",
      "patient_id: MCC009 , label: 1 , num_patch files: 1\n",
      "Batch 6\n",
      "Shape of patches: torch.Size([1, 8, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 8\n",
      "=====================================\n",
      "patient_id: MCC011 , label: 1 , num_patch files: 2\n",
      "Batch 7\n",
      "Shape of patches: torch.Size([1, 7, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 7\n",
      "=====================================\n",
      "patient_id: MCC012 , label: 1 , num_patch files: 5\n",
      "Batch 8\n",
      "Shape of patches: torch.Size([1, 83, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 83\n",
      "=====================================\n",
      "patient_id: MCC013 , label: 1 , num_patch files: 1\n",
      "Batch 9\n",
      "Shape of patches: torch.Size([1, 18, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 18\n",
      "=====================================\n",
      "patient_id: MCC014 , label: 1 , num_patch files: 1\n",
      "Batch 10\n",
      "Shape of patches: torch.Size([1, 9, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 9\n",
      "=====================================\n",
      "patient_id: MCC015 , label: 1 , num_patch files: 1\n",
      "Batch 11\n",
      "Shape of patches: torch.Size([1, 81, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 81\n",
      "=====================================\n",
      "patient_id: MCC016 , label: 1 , num_patch files: 2\n",
      "Batch 12\n",
      "Shape of patches: torch.Size([1, 93, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 93\n",
      "=====================================\n",
      "patient_id: MCC017 , label: 1 , num_patch files: 1\n",
      "Batch 13\n",
      "Shape of patches: torch.Size([1, 33, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 33\n",
      "=====================================\n",
      "patient_id: MCC018 , label: 1 , num_patch files: 1\n",
      "Batch 14\n",
      "Shape of patches: torch.Size([1, 13, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 13\n",
      "=====================================\n",
      "patient_id: MCC019 , label: 1 , num_patch files: 2\n",
      "Batch 15\n",
      "Shape of patches: torch.Size([1, 49, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 49\n",
      "=====================================\n",
      "patient_id: MCC021 , label: 1 , num_patch files: 2\n",
      "Batch 16\n",
      "Shape of patches: torch.Size([1, 37, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 37\n",
      "=====================================\n",
      "patient_id: MCC022 , label: 1 , num_patch files: 2\n",
      "Batch 17\n",
      "Shape of patches: torch.Size([1, 110, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 110\n",
      "=====================================\n",
      "patient_id: MCC023 , label: 1 , num_patch files: 1\n",
      "Batch 18\n",
      "Shape of patches: torch.Size([1, 20, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 20\n",
      "=====================================\n",
      "patient_id: MCC024 , label: 1 , num_patch files: 1\n",
      "Batch 19\n",
      "Shape of patches: torch.Size([1, 71, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 71\n",
      "=====================================\n",
      "patient_id: MCC025 , label: 0 , num_patch files: 2\n",
      "Batch 20\n",
      "Shape of patches: torch.Size([1, 27, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 27\n",
      "=====================================\n",
      "patient_id: MCC026 , label: 0 , num_patch files: 5\n",
      "Batch 21\n",
      "Shape of patches: torch.Size([1, 128, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 128\n",
      "=====================================\n",
      "patient_id: MCC028 , label: 1 , num_patch files: 1\n",
      "Batch 22\n",
      "Shape of patches: torch.Size([1, 11, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 11\n",
      "=====================================\n",
      "patient_id: MCC029 , label: 1 , num_patch files: 1\n",
      "Batch 23\n",
      "Shape of patches: torch.Size([1, 37, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 37\n",
      "=====================================\n",
      "patient_id: MCC032 , label: 1 , num_patch files: 3\n",
      "Batch 24\n",
      "Shape of patches: torch.Size([1, 71, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 71\n",
      "=====================================\n",
      "patient_id: MCC035 , label: 1 , num_patch files: 1\n",
      "Batch 25\n",
      "Shape of patches: torch.Size([1, 9, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 9\n",
      "=====================================\n",
      "patient_id: MCC047 , label: 1 , num_patch files: 2\n",
      "Batch 26\n",
      "Shape of patches: torch.Size([1, 27, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 27\n",
      "=====================================\n",
      "patient_id: MCC055 , label: 1 , num_patch files: 1\n",
      "Batch 27\n",
      "Shape of patches: torch.Size([1, 9, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 9\n",
      "=====================================\n",
      "patient_id: MCC059 , label: 1 , num_patch files: 1\n",
      "Batch 28\n",
      "Shape of patches: torch.Size([1, 44, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 44\n",
      "=====================================\n",
      "patient_id: MCC060 , label: 1 , num_patch files: 1\n",
      "Batch 29\n",
      "Shape of patches: torch.Size([1, 20, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 20\n",
      "=====================================\n",
      "patient_id: MCC061 , label: 1 , num_patch files: 1\n",
      "Batch 30\n",
      "Shape of patches: torch.Size([1, 43, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 43\n",
      "=====================================\n",
      "patient_id: MCC062 , label: 0 , num_patch files: 2\n",
      "Batch 31\n",
      "Shape of patches: torch.Size([1, 12, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 12\n",
      "=====================================\n",
      "patient_id: MCC069 , label: 0 , num_patch files: 1\n",
      "Batch 32\n",
      "Shape of patches: torch.Size([1, 10, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 10\n",
      "=====================================\n",
      "patient_id: MCC072 , label: 1 , num_patch files: 7\n",
      "Batch 33\n",
      "Shape of patches: torch.Size([1, 304, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 304\n",
      "=====================================\n",
      "patient_id: MCC075 , label: 1 , num_patch files: 6\n",
      "Batch 34\n",
      "Shape of patches: torch.Size([1, 69, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 69\n",
      "=====================================\n",
      "patient_id: MCC076 , label: 1 , num_patch files: 1\n",
      "Batch 35\n",
      "Shape of patches: torch.Size([1, 40, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 40\n",
      "=====================================\n",
      "patient_id: MCC077 , label: 1 , num_patch files: 3\n",
      "Batch 36\n",
      "Shape of patches: torch.Size([1, 153, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 153\n",
      "=====================================\n",
      "patient_id: MCC079 , label: 1 , num_patch files: 2\n",
      "Batch 37\n",
      "Shape of patches: torch.Size([1, 83, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 83\n",
      "=====================================\n",
      "patient_id: MCC080 , label: 1 , num_patch files: 6\n",
      "Batch 38\n",
      "Shape of patches: torch.Size([1, 235, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 235\n",
      "=====================================\n",
      "patient_id: MCC081 , label: 1 , num_patch files: 2\n",
      "Batch 39\n",
      "Shape of patches: torch.Size([1, 61, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 61\n",
      "=====================================\n",
      "patient_id: MCC082 , label: 1 , num_patch files: 2\n",
      "Batch 40\n",
      "Shape of patches: torch.Size([1, 179, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 179\n",
      "=====================================\n",
      "patient_id: MCC084 , label: 1 , num_patch files: 4\n",
      "Batch 41\n",
      "Shape of patches: torch.Size([1, 41, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 41\n",
      "=====================================\n",
      "patient_id: MCC087 , label: 1 , num_patch files: 5\n",
      "Batch 42\n",
      "Shape of patches: torch.Size([1, 214, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 214\n",
      "=====================================\n",
      "patient_id: MCC091 , label: 1 , num_patch files: 4\n",
      "Batch 43\n",
      "Shape of patches: torch.Size([1, 135, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 135\n",
      "=====================================\n",
      "patient_id: MCC093 , label: 0 , num_patch files: 2\n",
      "Batch 44\n",
      "Shape of patches: torch.Size([1, 76, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 76\n",
      "=====================================\n",
      "patient_id: MCC095 , label: 1 , num_patch files: 3\n",
      "Batch 45\n",
      "Shape of patches: torch.Size([1, 126, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 126\n",
      "=====================================\n",
      "patient_id: MCC096 , label: 0 , num_patch files: 1\n",
      "Batch 46\n",
      "Shape of patches: torch.Size([1, 37, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 37\n",
      "=====================================\n",
      "patient_id: MCC101 , label: 1 , num_patch files: 1\n",
      "Batch 47\n",
      "Shape of patches: torch.Size([1, 37, 100352])\n",
      "Label: tensor([1])\n",
      "Number of patches in this batch: 37\n",
      "=====================================\n",
      "patient_id: MCC112 , label: 0 , num_patch files: 1\n",
      "Batch 48\n",
      "Shape of patches: torch.Size([1, 8, 100352])\n",
      "Label: tensor([0])\n",
      "Number of patches in this batch: 8\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Path to the CSV file containing patient labels\n",
    "csv_file = '/home/80024223/data/cytology-some-data/unique-labels.csv'\n",
    "\n",
    "# Directory containing all the .npy patch files\n",
    "root_dir = '/mnt/Dept_MachineLearning/Faculty/Rasool, Ghulam/Shared Resources/HNC-Histopath-Embeddings/matched_patients'\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset = PatientPatchDataset(csv_file=csv_file, root_dir=root_dir)\n",
    "\n",
    "# Create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Function to test the DataLoader\n",
    "def test_dataloader(dataloader):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        patches, label = data['patches'], data['label']\n",
    "        print(f\"Batch {i+1}\")\n",
    "        print(f\"Shape of patches: {patches.shape}\")  # Expected shape: (batch_size, total_patches, 7, 7, 2048)\n",
    "        print(f\"Label: {label}\")\n",
    "        print(f\"Number of patches in this batch: {patches.shape[1]}\")  # total_patches\n",
    "        print(\"=====================================\")\n",
    "        \n",
    "        # To keep the test concise, let's only look at the first batch\n",
    "        # if i == 4:  # Look at the first batch only for testing\n",
    "        #     break\n",
    "\n",
    "# Call the test function\n",
    "test_dataloader(dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMIL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMIL, self).__init__()\n",
    "        # Update the input size to match the flattened patch size\n",
    "        self.fc1 = nn.Linear(100352, 500)  # Adjusted input size\n",
    "        self.fc2 = nn.Linear(500, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape is [batch_size, num_patches, num_features]\n",
    "        # No need to flatten x as it is already in the desired shape for processing\n",
    "        # We process each patch through the network, so reshape to (-1, num_features)\n",
    "        x = x.view(-1, 100352)  # Flatten the patches for each patient\n",
    "        \n",
    "        # Process each patch through the network\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        \n",
    "        # Reshape back to [batch_size, num_patches] to aggregate patch-level predictions\n",
    "        x = x.view(-1, x.size(0))  # Adjust the view based on how many patches were processed\n",
    "        \n",
    "        # Aggregate patch-level predictions to bag-level prediction\n",
    "        # Using max pooling as an example aggregation function. You might consider mean or custom pooling based on your task.\n",
    "        x, _ = torch.max(x, dim=1)  # dim=1 aggregates across patches\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_gpu(dataset, model, epochs=10, batch_size=5, learning_rate=0.001):\n",
    "    device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Training on {device}\")\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    model.to(device)  # Move model to the appropriate device\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data['patches'].float().to(device), data['label'].float().view(-1, 1).to(device)  # Move data to the appropriate device\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1)  # Ensure outputs are 1D to match labels' squeeze\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 10:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_cpu(dataset, model, epochs=10, batch_size=5, learning_rate=0.001):\n",
    "    print(f\"Training on CPU\")\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.BCELoss()\n",
    "\n",
    "    model.train()  # Set the model to training mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader):\n",
    "            inputs, labels = data['patches'].float(), data['label'].float().view(-1, 1)  # Ensure labels are correctly shaped\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            outputs = outputs.view(-1)  # Ensure outputs are 1D to match labels' squeeze\n",
    "            labels = labels.view(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 10 == 0:  # Print every 10 batches\n",
    "                print(f'Epoch {epoch + 1}, Batch {i + 1}, Loss: {running_loss / 10:.4f}')\n",
    "                running_loss = 0.0                \n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cuda:7\n",
      "Epoch 1, Batch 10, Loss: 80.8438\n",
      "Epoch 1, Batch 20, Loss: 90.0000\n",
      "Epoch 1, Batch 30, Loss: 90.0000\n",
      "Epoch 1, Batch 40, Loss: 80.0000\n",
      "Epoch 2, Batch 10, Loss: 80.0000\n",
      "Epoch 2, Batch 20, Loss: 90.0000\n",
      "Epoch 2, Batch 30, Loss: 90.0000\n",
      "Epoch 2, Batch 40, Loss: 80.0000\n",
      "Epoch 3, Batch 10, Loss: 80.0000\n",
      "Epoch 3, Batch 20, Loss: 90.0000\n",
      "Epoch 3, Batch 30, Loss: 90.0000\n",
      "Epoch 3, Batch 40, Loss: 80.0000\n",
      "Epoch 4, Batch 10, Loss: 80.0000\n",
      "Epoch 4, Batch 20, Loss: 90.0000\n",
      "Epoch 4, Batch 30, Loss: 90.0000\n",
      "Epoch 4, Batch 40, Loss: 80.0000\n",
      "Epoch 5, Batch 10, Loss: 80.0000\n",
      "Epoch 5, Batch 20, Loss: 90.0000\n",
      "Epoch 5, Batch 30, Loss: 90.0000\n",
      "Epoch 5, Batch 40, Loss: 80.0000\n",
      "Epoch 6, Batch 10, Loss: 80.0000\n",
      "Epoch 6, Batch 20, Loss: 90.0000\n",
      "Epoch 6, Batch 30, Loss: 90.0000\n",
      "Epoch 6, Batch 40, Loss: 80.0000\n",
      "Epoch 7, Batch 10, Loss: 80.0000\n",
      "Epoch 7, Batch 20, Loss: 90.0000\n",
      "Epoch 7, Batch 30, Loss: 90.0000\n",
      "Epoch 7, Batch 40, Loss: 80.0000\n",
      "Epoch 8, Batch 10, Loss: 80.0000\n",
      "Epoch 8, Batch 20, Loss: 90.0000\n",
      "Epoch 8, Batch 30, Loss: 90.0000\n",
      "Epoch 8, Batch 40, Loss: 80.0000\n",
      "Epoch 9, Batch 10, Loss: 80.0000\n",
      "Epoch 9, Batch 20, Loss: 90.0000\n",
      "Epoch 9, Batch 30, Loss: 90.0000\n",
      "Epoch 9, Batch 40, Loss: 80.0000\n",
      "Epoch 10, Batch 10, Loss: 80.0000\n",
      "Epoch 10, Batch 20, Loss: 90.0000\n",
      "Epoch 10, Batch 30, Loss: 90.0000\n",
      "Epoch 10, Batch 40, Loss: 80.0000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "dataset = PatientPatchDataset(csv_file='/mnt/Dept_MachineLearning/Faculty/Rasool, Ghulam/Shared Resources/HNC-Histopath-Embeddings/matched_patients/unique-labels.csv', root_dir='/mnt/Dept_MachineLearning/Faculty/Rasool, Ghulam/Shared Resources/HNC-Histopath-Embeddings/matched_patients/')\n",
    "model = SimpleMIL()\n",
    "# train_model_cpu(dataset, model, batch_size=1)\n",
    "train_model_gpu(dataset, model, batch_size=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GNN-MML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
